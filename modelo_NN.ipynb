{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import numpy                 as np\r\n",
    "import pandas                as pd\r\n",
    "import matplotlib.pyplot     as plt\r\n",
    "import seaborn               as sns\r\n",
    "\r\n",
    "def get_data():\r\n",
    "    stock = pd.read_csv('Data/ExistenciasNew.csv')\r\n",
    "    sales = pd.read_csv('Data/FacturacionCorregida.csv',parse_dates=['Fecha'],dayfirst=True ,sep=';')\r\n",
    "    products = pd.read_csv('Data/MaestroCorregido.csv', sep=';')\r\n",
    "    return stock, sales, products\r\n",
    "\r\n",
    "\r\n",
    "def clean_products(products):\r\n",
    "    products.columns = [column.upper() for column in products.columns]\r\n",
    "    products.columns = [column.lstrip('001-') for column in products.columns]\r\n",
    "    products.columns = [column.replace('.', '') for column in products.columns]\r\n",
    "    products.columns = [column.replace(' ', '_') for column in products.columns]\r\n",
    "    products.columns = [column.replace('_EXHIBIDO', '') for column in products.columns]\r\n",
    "    products.columns = [column.replace('_UNIFICADA', '') for column in products.columns]\r\n",
    "    products = products.rename(columns={\r\n",
    "        'DESC_ITEM':'DESC_LARGA',\r\n",
    "        'DESC_EXT_1_DETALLE':'DETALLE_1',\r\n",
    "        'DESC_EXT_2_DETALLE':'DETALLE_2',\r\n",
    "        'DESC_TIPO_INVENTARIO':'TIPO_INVENTARIO',\r\n",
    "        'DEPARTAMENTO':'CATEGORIA',\r\n",
    "        'MATERIAL_PPAL':'MATERIAL',\r\n",
    "        'PUESTOS':'PUESTOS_STR',\r\n",
    "        'NUM_PUESTOS':'PUESTOS',\r\n",
    "        'REF_COMBINADA':'REF',\r\n",
    "        'COLOR_DEF':'COLOR',\r\n",
    "    })\r\n",
    "\r\n",
    "    regex = '^([A-Z0-9]+\\s\\-\\s)+'\r\n",
    "    products.SUBCATEGORIA = products.SUBCATEGORIA.str.replace(regex,'',regex=True)\r\n",
    "    products.ORIGEN = products.ORIGEN.str.replace(regex,'',regex=True)\r\n",
    "    products.CATEGORIA = products.CATEGORIA.str.replace(regex,'',regex=True)\r\n",
    "    products.ESTILO = products.ESTILO.str.replace(regex,'',regex=True)\r\n",
    "    products.VIGENCIA = products.VIGENCIA.str.replace(regex,'',regex=True)\r\n",
    "    products.MATERIAL = products.MATERIAL.str.replace(regex,'',regex=True).str.upper()\r\n",
    "    products.ACABADO = products.ACABADO.str.upper().replace('SUPERFICIES MATE','MATE')\r\n",
    "    products.DETALLE_1.fillna('N/A',inplace=True)\r\n",
    "    products.DETALLE_2.fillna('N/A',inplace=True)\r\n",
    "    products['PUESTOS'] = products.PUESTOS_STR.str.slice(stop=1).replace({'N':0,'M':7}).astype(int).replace({0:np.nan})\r\n",
    "    products = products[['ITEM','REF','DESCRIPCION','CATEGORIA','SUBCATEGORIA','VIGENCIA','ORIGEN',\r\n",
    "                         'ESTILO','MATERIAL','ACABADO','PUESTOS','COLOR','ANCHO','ALTO','FONDO','DESC_LARGA']]\r\n",
    "    return products\r\n",
    "\r\n",
    "def clean_sales(sales):\r\n",
    "    sales.columns = [column.upper() for column in sales.columns]\r\n",
    "    sales.columns = [column.replace('.', '') for column in sales.columns]\r\n",
    "    sales.columns = [column.replace(' ', '_') for column in sales.columns]\r\n",
    "    sales = sales.groupby(['CO','DESC_CO','NRO_DOCUMENTO','REF_COMBINADA','FECHA'])[['CANTIDAD_INV','SUMA_DE_VLR_BRUTO','SUMA_DE_VLR_SUBTOTAL']].sum().reset_index()\r\n",
    "    sales['ID'] = sales['CO'].astype(str)+':'+sales['NRO_DOCUMENTO']+':'+sales['REF_COMBINADA']\r\n",
    "    sales[\"DESCUENTO(%)\"] = (sales['SUMA_DE_VLR_BRUTO']-sales['SUMA_DE_VLR_SUBTOTAL'])/sales['SUMA_DE_VLR_BRUTO']\r\n",
    "    sales['PRECIO'] = sales['SUMA_DE_VLR_BRUTO']/sales['CANTIDAD_INV']\r\n",
    "    sales['MES'] = sales['FECHA'].dt.month\r\n",
    "    sales['ANIO'] = sales['FECHA'].dt.year\r\n",
    "    sales['DIA'] = sales['FECHA'].dt.weekday\r\n",
    "    sales = sales.rename(columns={\r\n",
    "        'CO':'CODIGO_TIENDA',\r\n",
    "        'DESC_CO':'TIENDA',\r\n",
    "        'REF_COMBINADA':'PROD_REF',\r\n",
    "        'CANTIDAD_INV':'CANTIDAD',\r\n",
    "        'SUMA_DE_VLR_BRUTO':'SUBTOTAL',\r\n",
    "        'SUMA_DE_VLR_SUBTOTAL':'TOTAL',\r\n",
    "    })\r\n",
    "    sales = sales[['ID','NRO_DOCUMENTO','FECHA','CODIGO_TIENDA','TIENDA','PROD_REF','CANTIDAD','PRECIO',\r\n",
    "                   'SUBTOTAL','DESCUENTO(%)','TOTAL','ANIO','MES','DIA']]\r\n",
    "    return sales\r\n",
    "\r\n",
    "def clean_stock(stock):\r\n",
    "    stock.columns = [column.upper() for column in stock.columns]\r\n",
    "    stock.columns = [column.replace('.', '') for column in stock.columns]\r\n",
    "    stock.columns = [column.replace(' ', '_') for column in stock.columns]\r\n",
    "    \r\n",
    "    stock = stock.rename(columns={\r\n",
    "        'EXT_1_DETALLE':'DETALLE_1',\r\n",
    "        'EXT_2_DETALLE':'DETALLE_2',\r\n",
    "        'REF_COMBINADA':'REF',\r\n",
    "        'REFERENCIA':'ID',\r\n",
    "        'DISP':'CANTIDAD',\r\n",
    "        'DEPARTAMENTO':'CATEGORIA'\r\n",
    "    })\r\n",
    "    \r\n",
    "    regex = '^([A-Z0-9]+\\s\\-\\s)+'\r\n",
    "    stock.CATEGORIA = stock.CATEGORIA.str.replace(regex,'',regex=True)\r\n",
    "    stock.SUBCATEGORIA = stock.SUBCATEGORIA.str.replace(regex,'',regex=True)\r\n",
    "    \r\n",
    "    stock = stock[['ID','REF','CANTIDAD','CATEGORIA','SUBCATEGORIA','DETALLE_1','DETALLE_2']]\r\n",
    "    return stock\r\n",
    "\r\n",
    "def create_merges(sales,products):\r\n",
    "    sales_prod = sales.merge(products, left_on='PROD_REF', right_on='REF')\r\n",
    "    stock_prod = stock.drop(columns=['CATEGORIA','SUBCATEGORIA']).merge(products, on='REF', how='left')\r\n",
    "    return sales_prod, stock_prod\r\n",
    "\r\n",
    "def create_subcategories_list(sales_prod):\r\n",
    "    subcategories_list = []\r\n",
    "    temp = sales_prod.groupby('SUBCATEGORIA')[\"CANTIDAD\"].sum().sort_values(ascending=False)\r\n",
    "    totalSales = temp.sum()\r\n",
    "    pareto = totalSales*0.8\r\n",
    "    counter = 0\r\n",
    "    \r\n",
    "    temp = temp.to_frame().reset_index()\r\n",
    "    for index, row in temp.iterrows():\r\n",
    "        counter += row[\"CANTIDAD\"]\r\n",
    "        subcategories_list.append(row[\"SUBCATEGORIA\"])\r\n",
    "        if counter >= pareto:\r\n",
    "            break\r\n",
    "    return subcategories_list\r\n",
    "\r\n",
    "def create_materials_list(sales_prod):\r\n",
    "    materials_list = sales_prod.groupby(['MATERIAL'])['CANTIDAD'].sum().sort_values(ascending=False)\r\n",
    "    cumpperce = materials_list.cumsum()/materials_list.sum()*100\r\n",
    "    materials_list = cumpperce[cumpperce<91].to_frame().rename(columns={'CANTIDAD':'CANTIDAD(%)'})\r\n",
    "    return materials_list\r\n",
    "\r\n",
    "def create_consolidated(sales_prod):\r\n",
    "    consolidated = sales_prod.groupby('REF').aggregate(\r\n",
    "        CANTIDAD=pd.NamedAgg(column=\"CANTIDAD\", aggfunc=\"sum\"),\r\n",
    "        TOTAL=pd.NamedAgg(column=\"TOTAL\", aggfunc=\"sum\"), \r\n",
    "        PRECIO_PROMEDIO=pd.NamedAgg(column='PRECIO',aggfunc='mean'),\r\n",
    "        DESCUENTO_PROMEDIO=pd.NamedAgg(column='DESCUENTO(%)', aggfunc= 'mean')\r\n",
    "    ).reset_index().merge(products, on='REF').sort_values(by='CANTIDAD', ascending=False)\r\n",
    "    return consolidated\r\n",
    "\r\n",
    "def add_category_pos(row):\r\n",
    "    if row[\"SUBCATEGORIA\"] in subcategories_list:\r\n",
    "        index = row[\"SUBCATEGORIA\"]\r\n",
    "    else:\r\n",
    "        index = \"OTROS\"\r\n",
    "    return index\r\n",
    "\r\n",
    "def add_pos_cols(arr):\r\n",
    "    arr[\"SUBCATEGORIA_POS\"] = arr.apply(add_category_pos,axis = 1 )\r\n",
    "    arr['COLOR_POS'] = np.where(\r\n",
    "        arr[\"COLOR\"].isin(['NEGRO','GRIS','CAFE', 'BLANCO','AZUL','MIEL','BEIGE','CRISTAL','ROJO','AMARILLO']),\r\n",
    "        arr[\"COLOR\"],\r\n",
    "        'OTRO'\r\n",
    "    )\r\n",
    "    arr['MATERIAL_POS']=np.where(arr['MATERIAL'].isin(materials_list.index), arr['MATERIAL'], 'OTRO')\r\n",
    "    return\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "stock, sales, products = get_data()\r\n",
    "\r\n",
    "products = clean_products(products)\r\n",
    "sales = clean_sales(sales)\r\n",
    "stock = clean_stock(stock)\r\n",
    "\r\n",
    "sales_prod, stock_prod = create_merges(sales,products)\r\n",
    "groupby_sales = create_consolidated(sales_prod)\r\n",
    "\r\n",
    "subcategories_list = create_subcategories_list(sales_prod)\r\n",
    "materials_list = create_materials_list(sales_prod)\r\n",
    "\r\n",
    "add_pos_cols(sales_prod)\r\n",
    "add_pos_cols(products)\r\n",
    "add_pos_cols(stock_prod)\r\n",
    "add_pos_cols(groupby_sales)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Redes Neuronales"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocesamiento de datos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "sales_prod['dayofyear'] =  sales_prod['FECHA'].dt.dayofyear\r\n",
    "sales_prod['dayofweek'] =  sales_prod['FECHA'].dt.dayofweek\r\n",
    "\r\n",
    "basedate = pd.Timestamp('2019-01-02')\r\n",
    "sales_prod['dayssince2019'] = sales_prod.apply(lambda x: (x.FECHA - basedate).days, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "sales_prod = sales_prod.sort_values(by = \"FECHA\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "nn_data = sales_prod[['TIENDA','dayofyear','dayofweek','dayssince2019','ANIO','MES','DIA','CATEGORIA','SUBCATEGORIA',\r\n",
    "'ESTILO','MATERIAL','ACABADO','COLOR','ANCHO','ALTO','FONDO','CANTIDAD']]\r\n",
    "\r\n",
    "nn_data = pd.get_dummies(nn_data, drop_first  = True,columns = ['TIENDA','MES','CATEGORIA','SUBCATEGORIA','ESTILO','MATERIAL','ACABADO','COLOR'])\r\n",
    "\r\n",
    "nn_data = nn_data.dropna()\r\n",
    "\r\n",
    "X = nn_data\r\n",
    "y = np.asanyarray(nn_data.CANTIDAD)\r\n",
    "\r\n",
    "X_norm = StandardScaler().fit_transform(nn_data)\r\n",
    "y_norm = StandardScaler().fit_transform(y.reshape(-1,1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "X_train = X[X.ANIO != 2021]\r\n",
    "X_test = X[X.ANIO == 2021]\r\n",
    "\r\n",
    "y_train = y[nn_data.ANIO != 2021]\r\n",
    "y_test = y[nn_data.ANIO == 2021]\r\n",
    "\r\n",
    "X_train_norm = X_norm[nn_data.ANIO != 2021]\r\n",
    "X_test_norm = X_norm[nn_data.ANIO == 2021]\r\n",
    "\r\n",
    "y_train_norm = y_norm[nn_data.ANIO != 2021]\r\n",
    "y_test_norm = y_norm[nn_data.ANIO == 2021]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ARQUITECTURA RED NEURONAL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from tensorflow.keras.optimizers import SGD"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# define model\r\n",
    "model = Sequential()\r\n",
    "model.add(Dense(64, input_dim=170, activation='relu', kernel_initializer='he_uniform'))\r\n",
    "model.add(Dense(32, activation='sigmoid'))\r\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "opt = SGD(learning_rate=0.01, momentum=0.9)\r\n",
    "model.compile(loss='mean_squared_error', optimizer=opt)\r\n",
    "# fit model\r\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size = 10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/150\n",
      "3207/3207 [==============================] - 9s 2ms/step - loss: 1.7005 - val_loss: 0.9911\n",
      "Epoch 2/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6994 - val_loss: 0.9911\n",
      "Epoch 3/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6994 - val_loss: 0.9910\n",
      "Epoch 4/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6994 - val_loss: 0.9910\n",
      "Epoch 5/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 6/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 7/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 8/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 9/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 10/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 11/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 12/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 13/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 14/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 15/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 16/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 17/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 18/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 19/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 20/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 21/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 22/150\n",
      "3207/3207 [==============================] - 4s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 23/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 24/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 25/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 26/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 27/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 28/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 29/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 30/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 31/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 32/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 33/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 34/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 35/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 36/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 37/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 38/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 39/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 40/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 41/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 42/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 43/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 44/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 45/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 46/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 47/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 48/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 49/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 50/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 51/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 52/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 53/150\n",
      "3207/3207 [==============================] - 4s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 54/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 55/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 56/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 57/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 58/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 59/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 60/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 61/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 62/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 63/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 64/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 65/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 66/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 67/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 68/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 69/150\n",
      "3207/3207 [==============================] - 4s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 70/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 71/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 72/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 73/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 74/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 75/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 76/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 77/150\n",
      "3207/3207 [==============================] - 4s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 78/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 79/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 80/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 81/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 82/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 83/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 84/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 85/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 86/150\n",
      "3207/3207 [==============================] - 4s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 87/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 88/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 89/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 90/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 91/150\n",
      "3207/3207 [==============================] - 4s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 92/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 93/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 94/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 95/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 96/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 97/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 98/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 99/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 100/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 101/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 102/150\n",
      "3207/3207 [==============================] - 4s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 103/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 104/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 105/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 106/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 107/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 108/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 109/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 110/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 111/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 112/150\n",
      "3207/3207 [==============================] - 5s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 113/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 114/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 115/150\n",
      "3207/3207 [==============================] - 5s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 116/150\n",
      "3207/3207 [==============================] - 4s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 117/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 118/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 119/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 120/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 121/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 122/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 123/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 124/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 125/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 126/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 127/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 128/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 129/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 130/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 131/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 132/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 133/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 134/150\n",
      "3207/3207 [==============================] - 7s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 135/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 136/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 137/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 138/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 139/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 140/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 141/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 142/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 143/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 144/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 145/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 146/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 147/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 148/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 149/150\n",
      "3207/3207 [==============================] - 4s 1ms/step - loss: 1.6993 - val_loss: 0.9910\n",
      "Epoch 150/150\n",
      "3207/3207 [==============================] - 6s 2ms/step - loss: 1.6993 - val_loss: 0.9910\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# evaluate the model\r\n",
    "train_mse = model.evaluate(X_train, y_train, verbose=0)\r\n",
    "test_mse = model.evaluate(X_test, y_test, verbose=0)\r\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\r\n",
    "\r\n",
    "# plot loss during training\r\n",
    "plt.title('Loss / Mean Squared Error')\r\n",
    "plt.plot(history.history['loss'], label='train')\r\n",
    "plt.plot(history.history['val_loss'], label='test')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train: 1.699, Test: 0.991\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "2e0a58586f85eb97fbc15784b14674adf950cc960b3f0c3d06833bcca505dc72"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}